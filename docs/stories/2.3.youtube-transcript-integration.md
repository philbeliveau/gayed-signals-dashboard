# Story 2.3: youtube-transcript-integration

## Status
Draft

## Story
**As a** financial professional,
**I want** to analyze YouTube financial videos through transcript processing,
**so that** AutoGen agents can debate video content in the context of current Gayed signals.

## Acceptance Criteria
1. Existing YouTube transcript processing enhanced to trigger AutoGen financial agent debates
2. Current `/api/simple-youtube/` endpoint extended to support AutoGen conversation initiation
3. Video transcript extraction leverages existing `video-insights.ts` and content processing capabilities
4. Financial video content validation using existing relevance detection and filtering
5. Transcript processing integrates with existing performance monitoring and caching systems
6. Video metadata (title, channel, duration, view count) captured using current data structures
7. Transcript content optimized for AutoGen agent analysis with existing content formatting utilities
8. Integration maintains existing error handling and fallback mechanisms for video processing
9. Processed transcripts stored using existing database and session management infrastructure
10. YouTube content analysis triggers AutoGen debates using current signal context and market data
11. **DEPENDENCY**: Epic 1.1 AutoGen framework integration - **STATUS: Approved** ✅
12. **DEPENDENCY**: AutoGen conversation orchestrator from Epic 1.5 - **STATUS: Approved** ✅
13. **INFRASTRUCTURE**: Python backend with FastAPI required (not available on Vercel-only deployment)

## Tasks / Subtasks
- [ ] Enhance existing YouTube endpoint (AC: 1, 2)
  - [ ] Extend /api/simple-youtube/ for AutoGen integration
  - [ ] Add AutoGen conversation initiation capabilities
- [ ] Leverage existing transcript processing (AC: 3, 4)
  - [ ] Enhance video-insights.ts for AutoGen triggers
  - [ ] Use existing relevance detection and filtering
- [ ] Integrate with existing systems (AC: 5, 8, 9)
  - [ ] Connect to performance monitoring and caching
  - [ ] Maintain existing error handling and fallbacks
  - [ ] Use existing database and session management
- [ ] Capture and format content (AC: 6, 7)
  - [ ] Extract video metadata using current structures
  - [ ] Optimize transcript content for AutoGen analysis
- [ ] Connect to signal context (AC: 10)
  - [ ] Trigger AutoGen debates with current signal data
  - [ ] Integrate with existing market data context

## Dev Notes

### Relevant Source Tree Info
- `/src/app/api/simple-youtube/route.ts` - Next.js API route (Vercel fallback) ✅ VERIFIED
- `/backend/api/routes/simple_youtube.py` - Python FastAPI endpoint (actual processing) ✅ VERIFIED
- `/backend/services/youtube_service.py` - YouTube transcript extraction service ✅ VERIFIED
- `/src/shared/lib/api/video-insights.ts` - Video content processing utilities ✅ VERIFIED
- `/src/shared/types/video-insights.ts` - Type definitions for video data ✅ VERIFIED
- Performance monitoring and caching infrastructure ✅ VERIFIED

### AutoGen Integration Architecture
**TECHNICAL SPECIFICATIONS:**
- **AutoGen Framework**: Microsoft AutoGen 0.2+ integrated with existing Python FastAPI backend
- **Agent Implementation**: Convert existing financial agents to AutoGen ConversableAgent classes
- **Communication Pattern**: AutoGen GroupChat for Financial Analyst → Market Context → Risk Challenger
- **Integration Point**: `/backend/api/routes/simple_youtube.py` → AutoGen conversation → WebSocket stream
- **Transcript Processing**: yt-dlp + Whisper API → AutoGen message format + Gayed signal context
- **Response Format**: AutoGen conversation history + video metadata → Dashboard real-time display

**Python AutoGen Implementation:**
```python
from autogen import ConversableAgent, GroupChat, GroupChatManager

# Convert existing agents to AutoGen
financial_analyst = ConversableAgent(
    name="FinancialAnalyst",
    system_message="Analyze video content with current Gayed signals context",
    llm_config={"model": "gpt-4-turbo", "api_key": os.getenv("OPENAI_API_KEY")}
)

# GroupChat coordination
groupchat = GroupChat(
    agents=[financial_analyst, market_context, risk_challenger],
    messages=[],
    max_round=6,
    speaker_selection_method="round_robin"
)

# Conversation with video + signal context
conversation_result = await groupchat_manager.initiate_chat(
    message=f"Video Analysis: {transcript}\nCurrent Signals: {gayed_signals}"
)
```

### YouTube Integration Enhancement
Enhance existing capabilities to:
- Trigger AutoGen financial agent debates from video content
- Maintain current transcript extraction quality
- Preserve existing performance and caching benefits
- Integrate video analysis with signal context

### Content Optimization for AutoGen
Transcript content should be:
- Formatted for optimal agent analysis
- Combined with video metadata for context
- Validated for financial relevance
- Prepared with current signal context

### Technical Constraints & Error Handling
**System Constraints:**
- Preserve existing `/src/shared/lib/api/video-insights.ts` functionality
- Maintain compatibility with current Next.js API fallback routes
- FastAPI backend required for yt-dlp and Whisper API integration
- PostgreSQL storage for transcript caching and conversation history

**Error Handling & Fallback Mechanisms:**
```typescript
interface YouTubeProcessingError {
  code: 'VIDEO_UNAVAILABLE' | 'TRANSCRIPT_FAILED' | 'AUTOGEN_TIMEOUT' | 'RATE_LIMITED';
  message: string;
  fallbackAction: 'RETRY_LATER' | 'USE_CACHED' | 'MANUAL_REVIEW';
  retryAfter?: number;
}

// Graceful degradation strategy
const fallbackStrategies = {
  transcriptFailed: () => 'Use video title and description for basic analysis',
  autoGenTimeout: () => 'Return transcript with relevance score only',
  rateLimited: () => 'Queue for processing when limits reset'
};
```

**Security & Rate Limiting:**
- YouTube API quota management: 10,000 units/day allocation
- User rate limits: 3 videos/hour per user, 20 videos/day total
- Content validation: Financial relevance filtering before AutoGen trigger
- Input sanitization: URL validation, malicious link detection

### Performance Requirements & Monitoring
**Performance Specifications:**
- Video transcript extraction: <60s for 20-minute videos
- AutoGen conversation: <45s for 6-round agent debate
- Memory usage: <1GB for video processing, <500MB for conversation
- Concurrent processing: Support 5 simultaneous video analyses

**Monitoring & Metrics:**
- Real-time dashboards: Processing time, success rate, error categorization
- Resource monitoring: CPU usage, memory consumption, API rate limits
- Quality metrics: Transcript accuracy, financial relevance scores
- Alert thresholds: >90s processing time, >10% error rate, memory >80%

### Testing Framework
**Comprehensive Testing Strategy:**
- **Unit Tests**: Mock yt-dlp, Whisper API, AutoGen agents with pytest
- **Integration Tests**: Real YouTube URLs with mock AutoGen conversations
- **Performance Tests**: 10 concurrent videos, memory leak detection
- **Error Handling**: Invalid URLs, private videos, rate limiting scenarios
- **End-to-End**: YouTube URL → Transcript → Mock AutoGen → Dashboard display

**AutoGen Testing Implementation:**
```python
# Mock AutoGen for testing
@pytest.fixture
def mock_autogen_conversation():
    return {
        "messages": [
            {"agent": "FinancialAnalyst", "content": "Video shows bullish indicators..."},
            {"agent": "MarketContext", "content": "Current VIX suggests caution..."},
            {"agent": "RiskChallenger", "content": "Historical data contradicts..."}
        ],
        "consensus": "Mixed signals - proceed with caution",
        "confidence_score": 75
    }
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-21 | 1.0 | Initial story creation | John (PM) |

## Dev Agent Record
_(This section is owned by dev-agent and can only be modified by dev-agent)_

## QA Results
_(This section is owned by qa-agent and can only be modified by qa-agent)_